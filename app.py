import streamlit as st
import openai
import google.generativeai as genai

# -----------------------------------------------------------
# 1. ê¸°ë³¸ ì„¤ì • & ì„¸ì…˜ ì´ˆê¸°í™”
# -----------------------------------------------------------
st.set_page_config(page_title="MJP ë…¼ë¬¸ ë§ˆìŠ¤í„° (Full Ver.)", layout="wide")

# ë°ì´í„°ë¥¼ í˜ì´ì§€ë¼ë¦¬ ê³µìœ í•˜ê¸° ìœ„í•œ ì €ì¥ì†Œ
if 'research_context' not in st.session_state:
    st.session_state['research_context'] = {
        'topic': '',
        'variables': '',
        'method': '',
        'references': ''  # ê²€ìƒ‰ëœ ì›ë³¸ ìë£Œë“¤ì´ ì €ì¥ë¨
    }

# -----------------------------------------------------------
# 2. ì‚¬ì´ë“œë°”: ë¡œê·¸ì¸ & ì„¤ì •
# -----------------------------------------------------------
with st.sidebar:
    st.header("ğŸ” ì—°êµ¬ì‹¤ ì…ì¥")
    code = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password")
    if code not in st.secrets["ACCESS_CODES"]:
        st.warning("ì—°êµ¬ì› ì ‘ì† ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.")
        st.stop()
    st.success("Research System Online")

# API í‚¤ ì—°ê²°
openai.api_key = st.secrets["OPENAI_API_KEY"]
genai.configure(api_key=st.secrets["GEMINI_API_KEY"])

# -----------------------------------------------------------
# 3. AI ë‘ë‡Œ ì •ì˜ (ê° ë‹¨ê³„ë³„ ì „ë¬¸ê°€)
# -----------------------------------------------------------

# [Brain 1] ë³€ì¸ ì„¤ì •
def consult_variables(topic):
    prompt = f"""
    ë‹¹ì‹ ì€ ì‹¬ë¦¬í•™ ì—°êµ¬ ë°©ë²•ë¡  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì œ: '{topic}'
    ì´ ì£¼ì œë¥¼ ìœ„í•œ 'ë³€ì¸ êµ¬ì¡°(ë…ë¦½, ì¢…ì†, ì¡°ì ˆ/ë§¤ê°œ)'ë¥¼ 3ê°€ì§€ ì˜µì…˜ìœ¼ë¡œ ì œì•ˆí•˜ì„¸ìš”.
    """
    response = openai.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content

# [Brain 2] ì—°êµ¬ ë°©ë²•
def design_methodology(vars_text):
    prompt = f"""
    ë³€ì¸ êµ¬ì¡°: {vars_text}
    ìœ„ ë³€ì¸ì„ ì¸¡ì •í•˜ê¸° ìœ„í•œ 'ì²™ë„(Scale)'ì™€ 'í†µê³„ ë¶„ì„ ë°©ë²•'ì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì•ˆí•˜ì„¸ìš”.
    """
    response = openai.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content

# [Brain 3] ì„ í–‰ ì—°êµ¬ ê²€ìƒ‰ (Gemini 2.5)
def search_literature(topic, vars_text):
    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
        prompt = f"""
        ì£¼ì œ: {topic}
        ë³€ì¸: {vars_text}
        ìœ„ ì—°êµ¬ì™€ ê´€ë ¨ëœ 'í•µì‹¬ ì„ í–‰ ì—°êµ¬(2020-2026)' 5ê°œ ì´ìƒê³¼ 'ì£¼ìš” ì´ë¡ 'ì„ ì°¾ì•„ì£¼ì„¸ìš”.
        ê° ì—°êµ¬ì˜ ì €ì, ì—°ë„, ì£¼ìš” ê²°ê³¼ê°€ ëª…í™•íˆ ë“œëŸ¬ë‚˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.
        """
        response = model.generate_content(prompt)
        return response.text
    except:
        model = genai.GenerativeModel('gemini-pro')
        response = model.generate_content(prompt)
        return response.text

# [Brain 4] ë…¼ë¬¸ ì‘ì„±
def write_paper_final(section, context_data):
    prompt = f"""
    [ì—­í• ]: APA ìŠ¤íƒ€ì¼ ì‹¬ë¦¬í•™ ë…¼ë¬¸ ì—ë””í„°
    [ì±•í„°]: {section}
    [ì„ í–‰ ì—°êµ¬ ë°ì´í„°]: {context_data}
    
    ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë…¼ë¬¸ì˜ '{section}' íŒŒíŠ¸ë¥¼ í•™ìˆ ì ìœ¼ë¡œ ì„œìˆ í•˜ì„¸ìš”.
    ì¸ìš© í‘œê¸°(ì˜ˆ: Kim, 2023)ë¥¼ ì •í™•íˆ í¬í•¨í•˜ì„¸ìš”.
    """
    response = openai.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content

# [Brain 5] ì°¸ê³ ë¬¸í—Œ ì •ë¦¬ê¸° (NEW!)
def organize_references_apa(raw_text):
    prompt = f"""
    [ì—­í• ]: APA ì°¸ê³ ë¬¸í—Œ ì„œì§€ ì •ë³´ ì „ë¬¸ê°€
    
    [ì…ë ¥ëœ ì›ë³¸ ìë£Œ]:
    {raw_text}
    
    [ì‘ì—… ì§€ì‹œ]:
    1. ìœ„ í…ìŠ¤íŠ¸ì— ì–¸ê¸‰ëœ ëª¨ë“  ë…¼ë¬¸/ì €ì„œë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.
    2. ì¶”ì¶œëœ í•­ëª©ì„ 'APA 7íŒ ì–‘ì‹'ì— ë§ê²Œ ì™„ë²½í•˜ê²Œ ë³€í™˜í•˜ì„¸ìš”.
    3. ì •ë ¬ ìˆœì„œ:
       - 1ìˆœìœ„: ì €ìëª… ì•ŒíŒŒë²³ ìˆœ (A -> Z)
       - 2ìˆœìœ„: í•œê¸€ ì €ì ê°€ë‚˜ë‹¤ ìˆœ (ã„± -> ã…)
       - (ë˜ëŠ” APA ê·œì •ì— ë”°ë¼ í†µí•© ì •ë ¬)
    4. ì¶œë ¥ í˜•ì‹: ë²ˆí˜¸(1,2,3) ì—†ì´, ê¹”ë”í•œ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì¶œë ¥í•˜ì„¸ìš”.
    """
    response = openai.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content

# -----------------------------------------------------------
# 4. í™”ë©´ êµ¬ì„± (5ë‹¨ê³„ íƒ­)
# -----------------------------------------------------------
st.title("ğŸ“ MJP: ë…¼ë¬¸ ì™„ì„± ì˜¬ì¸ì› ì‹œìŠ¤í…œ")

# íƒ­ 5ê°œ ìƒì„±
tabs = st.tabs(["1. ë³€ì¸ ì„¤ì •", "2. ì—°êµ¬ ë°©ë²•", "3. ì„ í–‰ ì—°êµ¬", "4. ë…¼ë¬¸ ì‘ì„±", "5. ì°¸ê³ ë¬¸í—Œ(APA)"])

# [Tab 1] ë³€ì¸
with tabs[0]:
    st.header("ğŸ§  1ë‹¨ê³„: ë³€ì¸ ì„¤ê³„")
    topic = st.text_input("ì—°êµ¬ ì£¼ì œ ì…ë ¥")
    if st.button("êµ¬ì¡° ì œì•ˆ"):
        with st.spinner("ì„¤ê³„ ì¤‘..."):
            res = consult_variables(topic)
            st.markdown(res)
            st.session_state['research_context']['topic'] = topic
    
    final_vars = st.text_area("ğŸ“Œ ë³€ì¸ í™•ì • ì…ë ¥", height=100)
    if st.button("ë³€ì¸ ì €ì¥"):
        st.session_state['research_context']['variables'] = final_vars
        st.success("ì €ì¥ ì™„ë£Œ!")

# [Tab 2] ë°©ë²•
with tabs[1]:
    st.header("ğŸ“ 2ë‹¨ê³„: ë°©ë²•ë¡  ì„¤ê³„")
    if st.button("ì²™ë„ ì¶”ì²œ"):
        with st.spinner("ë¶„ì„ ì¤‘..."):
            res = design_methodology(st.session_state['research_context']['variables'])
            st.markdown(res)
    
    final_method = st.text_area("ğŸ“Œ ë°©ë²•ë¡  í™•ì • ì…ë ¥", height=100)
    if st.button("ë°©ë²• ì €ì¥"):
        st.session_state['research_context']['method'] = final_method
        st.success("ì €ì¥ ì™„ë£Œ!")

# [Tab 3] ì„ í–‰ ì—°êµ¬
with tabs[2]:
    st.header("ğŸ” 3ë‹¨ê³„: ê·¼ê±° ìë£Œ ìˆ˜ì§‘")
    if st.button("Gemini ê²€ìƒ‰ ì‹œì‘"):
        with st.spinner("ë…¼ë¬¸ ê²€ìƒ‰ ì¤‘..."):
            refs = search_literature(st.session_state['research_context']['topic'], 
                                   st.session_state['research_context']['variables'])
            st.text_area("ê²€ìƒ‰ ê²°ê³¼ (ì›ë³¸)", refs, height=500)
            st.session_state['research_context']['references'] = refs  # ì—¬ê¸°ì— ì €ì¥ëœ ê²Œ ë‚˜ì¤‘ì— ì°¸ê³ ë¬¸í—Œì´ ë¨

# [Tab 4] ë…¼ë¬¸ ì‘ì„±
with tabs[3]:
    st.header("âœï¸ 4ë‹¨ê³„: ë³¸ë¬¸ ì‘ì„±")
    section = st.selectbox("ì±•í„°", ["ì„œë¡ ", "ì´ë¡ ì  ë°°ê²½", "ë°©ë²•", "ê²°ê³¼", "ë…¼ì˜"])
    if st.button("ì´ˆì•ˆ ì‘ì„±"):
        with st.spinner("ì§‘í•„ ì¤‘..."):
            draft = write_paper_final(section, st.session_state['research_context']['references'])
            st.markdown(draft)

# [Tab 5] ì°¸ê³ ë¬¸í—Œ (NEW!)
with tabs[4]:
    st.header("ğŸ“š 5ë‹¨ê³„: ì°¸ê³ ë¬¸í—Œ ìë™ ì •ë¦¬ (APA)")
    st.info("3ë‹¨ê³„ì—ì„œ ê²€ìƒ‰ëœ ìë£Œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ APA ì–‘ì‹ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
    
    # ê²€ìƒ‰ëœ ìë£Œê°€ ìˆëŠ”ì§€ í™•ì¸
    raw_refs = st.session_state['research_context']['references']
    
    if not raw_refs:
        st.warning("âš ï¸ ì•„ì§ 3ë‹¨ê³„ì—ì„œ ì„ í–‰ ì—°êµ¬ ê²€ìƒ‰ì„ í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìë£Œê°€ ìˆì–´ì•¼ ì •ë¦¬ë¥¼ í•˜ì£ !")
    else:
        st.text_area("ìˆ˜ì§‘ëœ ì›ë³¸ ìë£Œ", raw_refs, height=150, disabled=True)
        
        if st.button("APA ìŠ¤íƒ€ì¼ë¡œ ë³€í™˜ ë° ì •ë ¬"):
            with st.spinner("ì €ìëª… A-Z / ê°€ë‚˜ë‹¤ ìˆœìœ¼ë¡œ ì •ë ¬ ì¤‘ì…ë‹ˆë‹¤..."):
                apa_list = organize_references_apa(raw_refs)
                st.success("ì°¸ê³ ë¬¸í—Œ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.markdown("### References")
                st.markdown(apa_list) # ì—¬ê¸°ê°€ ì§„ì§œ ê²°ê³¼ë¬¼
                st.code(apa_list, language='markdown') # ë³µì‚¬í•˜ê¸° ì¢‹ê²Œ ì½”ë“œ ë¸”ë¡ìœ¼ë¡œë„ ì œê³µ