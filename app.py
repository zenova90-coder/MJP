import streamlit as st
import openai
import google.generativeai as genai

# -----------------------------------------------------------
# 1. ê¸°ë³¸ ì„¤ì • & ì„¸ì…˜ ì´ˆê¸°í™”
# -----------------------------------------------------------
st.set_page_config(page_title="MJP ì—°êµ¬ íŒŒíŠ¸ë„ˆ (Pro Layout)", layout="wide")

# ì €ì¥ì†Œ ì´ˆê¸°í™”
if 'paper_sections' not in st.session_state:
    st.session_state['paper_sections'] = {
        "ì„œë¡ ": "", "ì´ë¡ ì  ë°°ê²½": "", "ì—°êµ¬ ë°©ë²•": "", "ê²°ê³¼": "", "ë…¼ì˜": ""
    }

if 'research_context' not in st.session_state:
    st.session_state['research_context'] = {
        'topic': '',
        'variables_options': [], # ì œì•ˆëœ ë³€ì¸ ì˜µì…˜ë“¤ì„ ì €ì¥í•  ê³³
        'variables': '',
        'method': '',
        'references': ''
    }

if "messages" not in st.session_state:
    st.session_state.messages = []

# -----------------------------------------------------------
# 2. ì‚¬ì´ë“œë°”: ë¡œê·¸ì¸ & ì„¤ì •
# -----------------------------------------------------------
with st.sidebar:
    st.header("ğŸ” ì—°êµ¬ì‹¤ ì…ì¥")
    code = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password")
    if code not in st.secrets["ACCESS_CODES"]:
        st.warning("ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.")
        st.stop()
    
    st.success("System Online")
    
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ë‚´ìš© ì§€ìš°ê¸°"):
        st.session_state.messages = []
        st.rerun()

# API í‚¤ ì—°ê²°
openai.api_key = st.secrets["OPENAI_API_KEY"]
genai.configure(api_key=st.secrets["GEMINI_API_KEY"])

# -----------------------------------------------------------
# 3. AI ë‘ë‡Œ (ê¸°ëŠ¥ ì •ì˜)
# -----------------------------------------------------------

def consult_variables_options(topic):
    # [í•µì‹¬] í´ë¦­ ì„ íƒì„ ìœ„í•´ AIì—ê²Œ "ì˜µì…˜ 3ê°œë§Œ ë”± ì¤˜"ë¼ê³  ì‹œí‚´ (êµ¬ë¶„ì ||| ì‚¬ìš©)
    prompt = f"""
    ì£¼ì œ '{topic}'ì— ì í•©í•œ ë³€ì¸ êµ¬ì¡°(ë…ë¦½/ì¢…ì†/ë§¤ê°œ ë“±)ë¥¼ 3ê°€ì§€ ì œì•ˆí•´ì£¼ì„¸ìš”.
    ê° ì˜µì…˜ì€ '|||'ë¡œ êµ¬ë¶„í•´ì„œ ì¶œë ¥í•˜ì„¸ìš”. ì„¤ëª…ì€ ì§§ê²Œ í•µì‹¬ë§Œ.
    ì˜ˆì‹œ:
    1ì•ˆ: IV-A, DV-B, MV-C ||| 2ì•ˆ: IV-X, DV-Y... ||| 3ì•ˆ: ...
    """
    response = openai.chat.completions.create(model="gpt-4o-mini", messages=[{"role": "user", "content": prompt}])
    # í…ìŠ¤íŠ¸ë¥¼ ||| ê¸°ì¤€ìœ¼ë¡œ ìª¼ê°œì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¦
    options = response.choices[0].message.content.split("|||")
    return [opt.strip() for opt in options if opt.strip()]

def design_methodology(vars_text):
    prompt = f"ë³€ì¸ '{vars_text}'ì„ ì¸¡ì •í•  ì²™ë„ì™€ í†µê³„ ë¶„ì„ ë°©ë²•ì„ ì œì•ˆí•´ì¤˜."
    response = openai.chat.completions.create(model="gpt-4o-mini", messages=[{"role": "user", "content": prompt}])
    return response.choices[0].message.content

def search_literature(topic, vars_text):
    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
        prompt = f"ì£¼ì œ: {topic}, ë³€ì¸: {vars_text}. ê´€ë ¨ ìµœì‹  ì„ í–‰ ì—°êµ¬(2020-2026)ì™€ í•µì‹¬ ì´ë¡  ìš”ì•½."
        return model.generate_content(prompt).text
    except:
        return "ê²€ìƒ‰ ì˜¤ë¥˜. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”."

def write_paper_final(section, context_data):
    prompt = f"""
    [ì—­í• ]: ë…¼ë¦¬ì ì´ê³  ë¹„íŒì ì¸ ì‹¬ë¦¬í•™ ì—°êµ¬ì.
    [ì‘ì—…]: '{section}' ì±•í„° ì‘ì„±.
    [ê·¼ê±°]: {context_data}
    [ì§€ì¹¨]: êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë‚˜ ë…¼ë¦¬ë¥¼ í¬í•¨í•˜ì—¬ APA ìŠ¤íƒ€ì¼ë¡œ ì‘ì„±.
    """
    response = openai.chat.completions.create(model="gpt-4o-mini", messages=[{"role": "user", "content": prompt}])
    return response.choices[0].message.content

def organize_references_apa(raw_text):
    prompt = f"ì°¸ê³ ë¬¸í—Œ ì¶”ì¶œ -> APA 7íŒ ë³€í™˜ -> ì•ŒíŒŒë²³/ê°€ë‚˜ë‹¤ ìˆœ ì •ë ¬:\n{raw_text}"
    response = openai.chat.completions.create(model="gpt-4o-mini", messages=[{"role": "user", "content": prompt}])
    return response.choices[0].message.content

# -----------------------------------------------------------
# 4. í™”ë©´ êµ¬ì„± (íƒ­ 5ê°œ - ì±„íŒ… íƒ­ì„ 4ë‹¨ê³„ë¡œ í†µí•©!)
# -----------------------------------------------------------
st.title("ğŸ“ MJP ì—°êµ¬ íŒŒíŠ¸ë„ˆ (Dual Mode)")

tabs = st.tabs(["1. ë³€ì¸ ì„ íƒ", "2. ë°©ë²• ì„¤ê³„", "3. ìë£Œ ê²€ìƒ‰", "4. ì‘ì„± & í”¼ë“œë°±", "5. ì°¸ê³ ë¬¸í—Œ"])

# [Tab 1] ë³€ì¸ (í´ë¦­ ì„ íƒ ê¸°ëŠ¥ ì¶”ê°€!)
with tabs[0]:
    st.header("ğŸ§  1ë‹¨ê³„: ë³€ì¸ ì•„ì´ë””ì–´ ì„ íƒ")
    topic = st.text_input("ì—°êµ¬ ì£¼ì œ")
    
    if st.button("ë³€ì¸ ì˜µì…˜ ì œì•ˆë°›ê¸°"):
        with st.spinner("GPTê°€ 3ê°€ì§€ ì—°êµ¬ ëª¨í˜•ì„ êµ¬ìƒ ì¤‘..."):
            options = consult_variables_options(topic)
            st.session_state['research_context']['variables_options'] = options
            st.session_state['research_context']['topic'] = topic
    
    # ì˜µì…˜ì´ ìƒì„±ë˜ì—ˆìœ¼ë©´ ì„ íƒì§€(Radio Button)ë¥¼ ë³´ì—¬ì¤Œ
    if st.session_state['research_context']['variables_options']:
        st.subheader("ë§ˆìŒì— ë“œëŠ” ì—°êµ¬ ëª¨í˜•ì„ ì„ íƒí•˜ì„¸ìš”:")
        choice = st.radio(
            "ì•„ë˜ ì˜µì…˜ ì¤‘ í•˜ë‚˜ë¥¼ í´ë¦­í•˜ì„¸ìš”:",
            st.session_state['research_context']['variables_options']
        )
        
        st.info(f"ì„ íƒëœ ëª¨í˜•: {choice}")
        
        # ì„ íƒí•˜ë©´ ìë™ìœ¼ë¡œ í™•ì • ì¹¸ì— ì±„ì›Œë„£ê¸°
        if st.button("ì´ ëª¨í˜•ìœ¼ë¡œ í™•ì • ë° ì €ì¥"):
            st.session_state['research_context']['variables'] = choice
            st.success("ë³€ì¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤! 2ë‹¨ê³„ë¡œ ë„˜ì–´ê°€ì„¸ìš”.")

# [Tab 2] ë°©ë²•
with tabs[1]:
    st.header("ğŸ“ 2ë‹¨ê³„: ë°©ë²•ë¡ ")
    if st.button("ë°©ë²•ë¡  ì œì•ˆ"): st.markdown(design_methodology(st.session_state['research_context']['variables']))
    final_method = st.text_area("ë°©ë²•ë¡  í™•ì •", key="m_input")
    if st.button("ë°©ë²• ì €ì¥"): st.session_state['research_context']['method'] = final_method

# [Tab 3] ê²€ìƒ‰
with tabs[2]:
    st.header("ğŸ” 3ë‹¨ê³„: ì„ í–‰ ì—°êµ¬")
    if st.button("Gemini ê²€ìƒ‰"):
        refs = search_literature(st.session_state['research_context']['topic'], st.session_state['research_context']['variables'])
        st.session_state['research_context']['references'] = refs
        st.text_area("ê²€ìƒ‰ ê²°ê³¼", refs)

# -----------------------------------------------------------
# [Tab 4] ì—¬ê¸°ê°€ í•µì‹¬! (ì—ë””í„° + ì±—ë´‡ ë™ì‹œ í™”ë©´)
# -----------------------------------------------------------
with tabs[3]:
    st.header("âœï¸ 4ë‹¨ê³„: ì‹¤ì‹œê°„ ì‘ì„± ë° í”¼ë“œë°±")
    
    # í™”ë©´ì„ 6:4 ë¹„ìœ¨ë¡œ ë‚˜ëˆ” (ì™¼ìª½: ê¸€ì“°ê¸° / ì˜¤ë¥¸ìª½: ì±„íŒ…)
    col_editor, col_chat = st.columns([6, 4])
    
    # --- [ì™¼ìª½] ë…¼ë¬¸ ì—ë””í„° ---
    with col_editor:
        st.subheader("ğŸ“ ì›ê³ ì§€ (Editor)")
        target_section = st.selectbox("ì‘ì„±í•  ì±•í„°", list(st.session_state['paper_sections'].keys()))
        
        if st.button("ğŸ¤– AI ì´ˆì•ˆ ìƒì„± (ì™¼ìª½)"):
            with st.spinner("ì‘ì„± ì¤‘..."):
                draft = write_paper_final(target_section, st.session_state['research_context']['references'])
                st.session_state['paper_sections'][target_section] = draft
        
        # ì—ë””í„° ì°½
        current_text = st.text_area(
            "ë‚´ìš© í¸ì§‘",
            value=st.session_state['paper_sections'][target_section],
            height=600
        )
        
        if st.button("ğŸ’¾ ë‚´ìš© ì €ì¥"):
            st.session_state['paper_sections'][target_section] = current_text
            st.success("ì €ì¥ë¨")

    # --- [ì˜¤ë¥¸ìª½] AI ì§€ë„êµìˆ˜ (ì±„íŒ…) ---
    with col_chat:
        st.subheader("ğŸ’¬ ì§€ë„êµìˆ˜ í”¼ë“œë°±")
        st.info("ì™¼ìª½ ê¸€ì„ ë³´ê³  ìˆ˜ì •ì‚¬í•­ì„ ë§í•˜ì„¸ìš”.")
        
        # ì±„íŒ…ì°½ ìŠ¤íƒ€ì¼ë§ (ë†’ì´ ì œí•œ)
        with st.container(height=500):
            for message in st.session_state.messages:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])

        # ì±„íŒ… ì…ë ¥
        if prompt := st.chat_input("ì˜ˆ: ì„œë¡ ì˜ ë‘ ë²ˆì§¸ ë¬¸ë‹¨ í†µê³„ê°€ ë¶€ì¡±í•´."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            
            # AI ë‹µë³€ ìƒì„±
            # [ì¤‘ìš”] í˜„ì¬ ì—ë””í„°ì— ìˆëŠ” ê¸€ì„ ë§¥ë½ìœ¼ë¡œ ê°™ì´ ë³´ëƒ„
            full_context = f"""
            [í˜„ì¬ ì‚¬ìš©ìê°€ ë³´ê³  ìˆëŠ” ê¸€ ({target_section})]:
            {st.session_state['paper_sections'][target_section]}
            
            [ì‚¬ìš©ì ìš”ì²­]: {prompt}
            """
            
            # ì±—ë´‡ ì‘ë‹µ ìƒì„±
            response = openai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "system", "content": "ë‹¹ì‹ ì€ ë…¼ë¬¸ ì§€ë„êµìˆ˜ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìš”ì²­ì— ë”°ë¼ ì™¼ìª½ì˜ ê¸€ì„ ìˆ˜ì •í•˜ê±°ë‚˜ ì¡°ì–¸ì„ í•´ì£¼ì„¸ìš”."}] + 
                         [{"role": "user", "content": full_context}]
            )
            
            ai_msg = response.choices[0].message.content
            st.session_state.messages.append({"role": "assistant", "content": ai_msg})
            st.rerun() # ì±„íŒ… ì˜¬ë¼ê°€ê²Œ ìƒˆë¡œê³ ì¹¨

# [Tab 5] ì°¸ê³ ë¬¸í—Œ
with tabs[4]:
    st.header("ğŸ“š 5ë‹¨ê³„: ì°¸ê³ ë¬¸í—Œ")
    if st.button("APA ë³€í™˜"):
        st.markdown(organize_references_apa(st.session_state['research_context']['references']))