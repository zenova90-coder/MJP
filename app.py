import streamlit as st
import openai
import google.generativeai as genai

# -----------------------------------------------------------
# 1. ìŠ¤íƒ€ì¼ & ê¸°ë³¸ ì„¤ì •
# -----------------------------------------------------------
st.set_page_config(page_title="MJP Pro: ì—°êµ¬ íŒŒíŠ¸ë„ˆ", layout="wide")

# [ë””ìì¸] ë²„íŠ¼ ìƒ‰ìƒ ê°•ì œ ë³€ê²½ (CSS)
# ì¼ë°˜ ë²„íŠ¼ì€ íŒŒë€ìƒ‰ ê³„ì—´, ë§ˆìš°ìŠ¤ ì˜¬ë¦¬ë©´ ì§„í•´ì§€ê²Œ ì„¤ì •
st.markdown("""
<style>
    div.stButton > button:first-child {
        background-color: #0068c9;
        color: white;
        border-radius: 8px;
        border: none;
        font-weight: bold;
    }
    div.stButton > button:first-child:hover {
        background-color: #004b91;
        color: white;
    }
    /* íƒ­ ê¸€ì”¨ í¬ê¸° í‚¤ìš°ê¸° */
    button[data-baseweb="tab"] {
        font-size: 16px;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

# -----------------------------------------------------------
# 2. ë°ì´í„° ì €ì¥ì†Œ(ì„¸ì…˜) ì´ˆê¸°í™”
# -----------------------------------------------------------
if 'paper_sections' not in st.session_state:
    st.session_state['paper_sections'] = {
        "ì„œë¡ ": "", "ì´ë¡ ì  ë°°ê²½": "", "ì—°êµ¬ ë°©ë²•": "", "ê²°ê³¼": "", "ë…¼ì˜": ""
    }

if 'research_context' not in st.session_state:
    st.session_state['research_context'] = {
        'topic': '',
        'variables_options': [], 
        'variables': '', # í™•ì •ëœ ë³€ì¸
        'method_options': [], # [NEW] ë°©ë²•ë¡  ì˜µì…˜ë“¤
        'method': '',    # í™•ì •ëœ ë°©ë²•ë¡ 
        'references': ''
    }

# ê° ë‹¨ê³„ë³„ ì±„íŒ… ê¸°ë¡ì„ ë”°ë¡œ ì €ì¥í• ê¹Œ í•˜ë‹¤ê°€, ì—°ì†ì„±ì„ ìœ„í•´ í†µí•© ì €ì¥
if "messages" not in st.session_state:
    st.session_state.messages = []

# -----------------------------------------------------------
# 3. ë¡œê·¸ì¸ & ì„¤ì •
# -----------------------------------------------------------
with st.sidebar:
    st.header("ğŸ” ì—°êµ¬ì‹¤ ì…ì¥")
    code = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password")
    if code not in st.secrets["ACCESS_CODES"]:
        st.warning("ì—°êµ¬ì› ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.")
        st.stop()
    st.success("System Online")
    
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ë‚´ìš© ì´ˆê¸°í™”", type="primary"):
        st.session_state.messages = []
        st.rerun()

openai.api_key = st.secrets["OPENAI_API_KEY"]
genai.configure(api_key=st.secrets["GEMINI_API_KEY"])

# -----------------------------------------------------------
# 4. AI ê¸°ëŠ¥ ì •ì˜ (ì˜µì…˜ ìƒì„±ê¸° ê°•í™”)
# -----------------------------------------------------------

def consult_variables_options(topic):
    prompt = f"""
    ì£¼ì œ '{topic}'ì— ì í•©í•œ ë³€ì¸ êµ¬ì¡°(ë…ë¦½/ì¢…ì†/ë§¤ê°œ ë“±)ë¥¼ 3ê°€ì§€ ì œì•ˆí•´ì£¼ì„¸ìš”.
    ê° ì˜µì…˜ì€ '|||'ë¡œ êµ¬ë¶„í•´ì„œ ì¶œë ¥í•˜ì„¸ìš”. ì„¤ëª…ì€ í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ.
    ì˜ˆ: 1ì•ˆ: ... ||| 2ì•ˆ: ... ||| 3ì•ˆ: ...
    """
    response = openai.chat.completions.create(model="gpt-4o-mini", messages=[{"role": "user", "content": prompt}])
    return [opt.strip() for opt in response.choices[0].message.content.split("|||") if opt.strip()]

def design_methodology_options(vars_text):
    # [NEW] ë°©ë²•ë¡ ë„ 3ê°€ì§€ ì˜µì…˜ìœ¼ë¡œ ì œì•ˆë°›ê¸°
    prompt = f"""
    ë³€ì¸ êµ¬ì¡°: '{vars_text}'
    ì´ ë³€ì¸ì„ ì—°êµ¬í•˜ê¸° ìœ„í•œ 'ì²™ë„(ì¸¡ì •ë„êµ¬)'ì™€ 'í†µê³„ ë¶„ì„ ë°©ë²•' ì¡°í•©ì„ 3ê°€ì§€ ì œì•ˆí•´ì£¼ì„¸ìš”.
    ê° ì˜µì…˜ì€ '|||'ë¡œ êµ¬ë¶„í•´ì„œ ì¶œë ¥í•˜ì„¸ìš”.
    ì˜ˆ: 1ì•ˆ: (ì²™ë„ A, B + íšŒê·€ë¶„ì„) ||| 2ì•ˆ: (ì²™ë„ A, B + êµ¬ì¡°ë°©ì •ì‹) ||| 3ì•ˆ: ...
    """
    response = openai.chat.completions.create(model="gpt-4o-mini", messages=[{"role": "user", "content": prompt}])
    return [opt.strip() for opt in response.choices[0].message.content.split("|||") if opt.strip()]

def search_literature(topic, vars_text):
    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
        prompt = f"ì£¼ì œ: {topic}, ë³€ì¸: {vars_text}. ê´€ë ¨ ìµœì‹  ì„ í–‰ ì—°êµ¬(2020-2026)ì™€ í•µì‹¬ ì´ë¡  ìš”ì•½."
        return model.generate_content(prompt).text
    except:
        return "ê²€ìƒ‰ ì˜¤ë¥˜. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”."

def write_paper_final(section, context_data):
    prompt = f"""
    [ì—­í• ]: ë…¼ë¦¬ì ì´ê³  ë¹„íŒì ì¸ ì‹¬ë¦¬í•™ ì—°êµ¬ì.
    [ì‘ì—…]: '{section}' ì±•í„° ì‘ì„±.
    [ê·¼ê±°]: {context_data}
    [ì§€ì¹¨]: êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë‚˜ ë…¼ë¦¬ë¥¼ í¬í•¨í•˜ì—¬ APA ìŠ¤íƒ€ì¼ë¡œ ì‘ì„±.
    """
    response = openai.chat.completions.create(model="gpt-4o-mini", messages=[{"role": "user", "content": prompt}])
    return response.choices[0].message.content

def organize_references_apa(raw_text):
    prompt = f"ì°¸ê³ ë¬¸í—Œ ì¶”ì¶œ -> APA 7íŒ ë³€í™˜ -> ì•ŒíŒŒë²³/ê°€ë‚˜ë‹¤ ìˆœ ì •ë ¬:\n{raw_text}"
    response = openai.chat.completions.create(model="gpt-4o-mini", messages=[{"role": "user", "content": prompt}])
    return response.choices[0].message.content

# -----------------------------------------------------------
# 5. ê³µí†µ ì»´í¬ë„ŒíŠ¸: ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤ (ëª¨ë“  íƒ­ì— ë“¤ì–´ê°ˆ ë…€ì„)
# -----------------------------------------------------------
def render_chat_interface(stage_name, context_text):
    st.markdown(f"#### ğŸ’¬ AI í”¼ë“œë°± ({stage_name})")
    st.caption("ì™¼ìª½ ë‚´ìš©ì„ ë³´ë©° ì§ˆë¬¸í•˜ê±°ë‚˜ ìˆ˜ì •ì„ ìš”ì²­í•˜ì„¸ìš”.")
    
    # ì±„íŒ…ì°½ ë†’ì´ ê³ ì •
    with st.container(height=450):
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

    if prompt := st.chat_input(f"{stage_name}ì— ëŒ€í•´ ì§ˆë¬¸í•˜ê¸°..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        # AIì—ê²Œ ë³´ë‚¼ ë§¥ë½ êµ¬ì„±
        full_context = f"""
        [í˜„ì¬ ì‘ì—… ë‹¨ê³„]: {stage_name}
        [ì‚¬ìš©ìê°€ ë³´ê³  ìˆëŠ” ë‚´ìš©]: 
        {context_text[:1000]}... (ìƒëµ)
        
        [ì‚¬ìš©ì ì§ˆë¬¸]: {prompt}
        """
        
        # ì±—ë´‡ ì‘ë‹µ
        response = openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "system", "content": "ë‹¹ì‹ ì€ ë…¼ë¬¸ ì§€ë„êµìˆ˜ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì‘ì—…ë¬¼ì„ ê²€í† í•˜ê³  ì¡°ì–¸í•˜ì„¸ìš”."}] + 
                     [{"role": "user", "content": full_context}]
        )
        ai_msg = response.choices[0].message.content
        st.session_state.messages.append({"role": "assistant", "content": ai_msg})
        st.rerun()

# -----------------------------------------------------------
# 6. ë©”ì¸ í™”ë©´ êµ¬ì„±
# -----------------------------------------------------------
st.title("ğŸ“ MJP Pro: ì—°êµ¬ íŒŒíŠ¸ë„ˆ")

tabs = st.tabs(["1. ë³€ì¸ ì„¤ì •", "2. ë°©ë²•ë¡  ì„¤ê³„", "3. ìë£Œ ê²€ìƒ‰", "4. ë³¸ë¬¸ ì‘ì„±", "5. ì°¸ê³ ë¬¸í—Œ"])

# ===========================================================
# [Tab 1] ë³€ì¸ ì„¤ì • (ì…ë ¥ ìš°ì„  + ì„ íƒ ì˜µì…˜)
# ===========================================================
with tabs[0]:
    col_main, col_chat = st.columns([6, 4])
    
    with col_main:
        st.subheader("ğŸ§  1ë‹¨ê³„: ë³€ì¸ í™•ì •")
        
        # [1] ì‚¬ìš©ìê°€ ì§ì ‘ ì…ë ¥í•˜ëŠ” ê³³ (ê°€ì¥ ìœ„!)
        st.caption("ì•„ë˜ ì¹¸ì— ì—°êµ¬í•  ë³€ì¸ì„ ì§ì ‘ ì ê±°ë‚˜, ë°‘ì—ì„œ AI ì œì•ˆì„ ê³¨ë¼ ì±„ì›Œë„£ìœ¼ì„¸ìš”.")
        final_vars = st.text_area("ğŸ“Œ ìµœì¢… ë³€ì¸ ì…ë ¥ë€", 
                                value=st.session_state['research_context']['variables'], 
                                height=150,
                                key="input_vars")
        
        # ì €ì¥ ë²„íŠ¼ (ëˆˆì— ë„ê²Œ)
        if st.button("âœ… ë³€ì¸ ë‚´ìš© ì €ì¥í•˜ê¸°", type="primary"):
            st.session_state['research_context']['variables'] = final_vars
            st.success("ë³€ì¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤! (ì˜¤ë¥¸ìª½ ì±„íŒ…ì°½ì—ì„œ ì ê²€í•´ë³´ì„¸ìš”)")

        st.markdown("---")
        
        # [2] AI ì œì•ˆ ì˜ì—­ (ì•„ë˜ìª½)
        st.info("ğŸ’¡ ì•„ì´ë””ì–´ê°€ í•„ìš”í•˜ì‹ ê°€ìš”? ì•„ë˜ì—ì„œ AIì˜ ì œì•ˆì„ ë°›ì•„ë³´ì„¸ìš”.")
        topic = st.text_input("ì—°êµ¬ ì£¼ì œ í‚¤ì›Œë“œ (ì˜ˆ: ì§ë¬´ ìŠ¤íŠ¸ë ˆìŠ¤)")
        
        if st.button("ğŸ¤– ë³€ì¸ êµ¬ì¡° 3ê°€ì§€ ì œì•ˆë°›ê¸°"):
            with st.spinner("AIê°€ ì•„ì´ë””ì–´ë¥¼ ì§œë‚´ëŠ” ì¤‘..."):
                options = consult_variables_options(topic)
                st.session_state['research_context']['variables_options'] = options
                st.session_state['research_context']['topic'] = topic
        
        # ì˜µì…˜ì´ ìˆìœ¼ë©´ ë³´ì—¬ì¤Œ
        if st.session_state['research_context']['variables_options']:
            choice = st.radio("ë§ˆìŒì— ë“œëŠ” ì•ˆì„ ì„ íƒí•˜ì„¸ìš”:", st.session_state['research_context']['variables_options'])
            
            if st.button("ğŸ”¼ ìœ„ ì…ë ¥ë€ì— ì ìš©í•˜ê¸°"):
                # ì„ íƒí•œ ë‚´ìš©ì„ ìœ„ìª½ text_areaì— ë°˜ì˜ (ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸)
                st.session_state['research_context']['variables'] = choice
                st.rerun() # í™”ë©´ ìƒˆë¡œê³ ì¹¨í•´ì„œ ë°˜ì˜

    with col_chat:
        # í˜„ì¬ ì…ë ¥ëœ ë³€ì¸ì„ ë§¥ë½ìœ¼ë¡œ ì±„íŒ…
        render_chat_interface("1ë‹¨ê³„(ë³€ì¸)", st.session_state['research_context']['variables'])


# ===========================================================
# [Tab 2] ë°©ë²•ë¡  ì„¤ê³„ (ì…ë ¥ ìš°ì„  + ì„ íƒ ì˜µì…˜ ë„ì…!)
# ===========================================================
with tabs[1]:
    col_main, col_chat = st.columns([6, 4])
    
    with col_main:
        st.subheader("ğŸ“ 2ë‹¨ê³„: ì—°êµ¬ ë°©ë²• í™•ì •")
        
        # [1] ì‚¬ìš©ì ì…ë ¥ë€ (ìµœìš°ì„ )
        st.caption("ì‚¬ìš©í•  ì²™ë„ì™€ ë¶„ì„ ë°©ë²•ì„ ì§ì ‘ ì ê±°ë‚˜, AI ì¶”ì²œì„ ë°›ìœ¼ì„¸ìš”.")
        final_method = st.text_area("ğŸ“Œ ìµœì¢… ë°©ë²•ë¡  ì…ë ¥ë€", 
                                  value=st.session_state['research_context']['method'], 
                                  height=150,
                                  key="input_method")
        
        if st.button("âœ… ë°©ë²•ë¡  ë‚´ìš© ì €ì¥í•˜ê¸°", type="primary", key="save_method"):
            st.session_state['research_context']['method'] = final_method
            st.success("ë°©ë²•ë¡ ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

        st.markdown("---")
        
        # [2] AI ì œì•ˆ ì˜ì—­
        st.info("ğŸ’¡ ì ì ˆí•œ ì²™ë„ì™€ í†µê³„ë²•ì„ ì¶”ì²œí•´ ë“œë¦½ë‹ˆë‹¤.")
        
        # 1ë‹¨ê³„ì—ì„œ ì •í•œ ë³€ì¸ì„ ê°€ì ¸ì™€ì„œ ë³´ì—¬ì¤Œ
        current_vars = st.session_state['research_context']['variables']
        st.write(f"í˜„ì¬ ì„¤ì •ëœ ë³€ì¸: **{current_vars if current_vars else '(ë³€ì¸ ë¯¸ì„¤ì •)'}**")
        
        if st.button("ğŸ¤– ë°©ë²•ë¡  3ê°€ì§€ ì œì•ˆë°›ê¸°"):
            if not current_vars:
                st.error("1ë‹¨ê³„ì—ì„œ ë³€ì¸ì„ ë¨¼ì € ì •í•´ì£¼ì„¸ìš”!")
            else:
                with st.spinner("í†µê³„ ë°©ë²•ë¡  ì„¤ê³„ ì¤‘..."):
                    opts = design_methodology_options(current_vars)
                    st.session_state['research_context']['method_options'] = opts
        
        if st.session_state['research_context']['method_options']:
            method_choice = st.radio("ê°€ì¥ ì ì ˆí•œ ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”:", st.session_state['research_context']['method_options'])
            
            if st.button("ğŸ”¼ ìœ„ ì…ë ¥ë€ì— ì ìš©í•˜ê¸°", key="apply_method"):
                st.session_state['research_context']['method'] = method_choice
                st.rerun()

    with col_chat:
        render_chat_interface("2ë‹¨ê³„(ë°©ë²•ë¡ )", st.session_state['research_context']['method'])


# ===========================================================
# [Tab 3] ìë£Œ ê²€ìƒ‰ (Split View ì ìš©)
# ===========================================================
with tabs[2]:
    col_main, col_chat = st.columns([6, 4])
    
    with col_main:
        st.subheader("ğŸ” 3ë‹¨ê³„: ì„ í–‰ ì—°êµ¬ ìˆ˜ì§‘")
        
        if st.button("ğŸš€ Gemini ê²€ìƒ‰ ì‹œì‘", type="primary"):
            # ì£¼ì œì™€ ë³€ì¸ ì •ë³´ë¥¼ í•©ì³ì„œ ê²€ìƒ‰
            t = st.session_state['research_context']['topic']
            v = st.session_state['research_context']['variables']
            if not t or not v:
                st.warning("1ë‹¨ê³„ì—ì„œ ì£¼ì œì™€ ë³€ì¸ì„ ë¨¼ì € ì„¤ì •í•´ì•¼ ì •í™•í•œ ê²€ìƒ‰ì´ ë©ë‹ˆë‹¤.")
            else:
                with st.spinner("ë…¼ë¬¸ì„ ì½ê³  ìˆìŠµë‹ˆë‹¤..."):
                    refs = search_literature(t, v)
                    st.session_state['research_context']['references'] = refs
        
        # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
        refs_content = st.session_state['research_context']['references']
        st.text_area("ê²€ìƒ‰ ê²°ê³¼ (Raw Data)", value=refs_content, height=500)

    with col_chat:
        render_chat_interface("3ë‹¨ê³„(ê²€ìƒ‰)", st.session_state['research_context']['references'])


# ===========================================================
# [Tab 4] ë³¸ë¬¸ ì‘ì„± (Split View ìœ ì§€)
# ===========================================================
with tabs[3]:
    col_main, col_chat = st.columns([6, 4])
    
    with col_main:
        st.subheader("âœï¸ 4ë‹¨ê³„: ë³¸ë¬¸ ì‘ì„±")
        target_section = st.selectbox("ì‘ì„±í•  ì±•í„°", list(st.session_state['paper_sections'].keys()))
        
        if st.button(f"ğŸ¤– {target_section} ì´ˆì•ˆ ìƒì„±", type="primary"):
            with st.spinner("ì‘ì„± ì¤‘..."):
                draft = write_paper_final(target_section, st.session_state['research_context']['references'])
                st.session_state['paper_sections'][target_section] = draft
                st.rerun()
        
        # ì—ë””í„°
        current_text = st.text_area(
            f"ğŸ“ {target_section} í¸ì§‘ê¸°",
            value=st.session_state['paper_sections'][target_section],
            height=600
        )
        
        if st.button("ğŸ’¾ ë‚´ìš© ì €ì¥"):
            st.session_state['paper_sections'][target_section] = current_text
            st.success("ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    with col_chat:
        # í˜„ì¬ ì—ë””í„°ì— ìˆëŠ” ê¸€ì„ ë§¥ë½ìœ¼ë¡œ ì „ë‹¬
        render_chat_interface(f"4ë‹¨ê³„({target_section})", st.session_state['paper_sections'][target_section])


# ===========================================================
# [Tab 5] ì°¸ê³ ë¬¸í—Œ (Split View ì ìš©)
# ===========================================================
with tabs[4]:
    col_main, col_chat = st.columns([6, 4])
    
    with col_main:
        st.subheader("ğŸ“š 5ë‹¨ê³„: APA ì°¸ê³ ë¬¸í—Œ ì •ë¦¬")
        if st.button("âœ¨ APA ìŠ¤íƒ€ì¼ë¡œ ë³€í™˜ ë° ì •ë ¬", type="primary"):
            if not st.session_state['research_context']['references']:
                st.error("3ë‹¨ê³„ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                with st.spinner("ì •ë ¬ ì¤‘..."):
                    apa_list = organize_references_apa(st.session_state['research_context']['references'])
                    st.markdown(apa_list)
                    st.code(apa_list) # ë³µì‚¬ìš©

    with col_chat:
        render_chat_interface("5ë‹¨ê³„(ì°¸ê³ ë¬¸í—Œ)", "APA ìŠ¤íƒ€ì¼ ë³€í™˜ ì‘ì—… ì¤‘...")