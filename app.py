import streamlit as st
import openai
import google.generativeai as genai

# -----------------------------------------------------------
# 1. ê¸°ë³¸ ì„¤ì • & ì„¸ì…˜ ì´ˆê¸°í™”
# -----------------------------------------------------------
st.set_page_config(page_title="MJP ì—°êµ¬ ì„¤ê³„ íŒŒíŠ¸ë„ˆ", layout="wide")

# ë°ì´í„°ë¥¼ í˜ì´ì§€ë¼ë¦¬ ê³µìœ í•˜ê¸° ìœ„í•œ ì €ì¥ì†Œ ì´ˆê¸°í™”
if 'research_context' not in st.session_state:
    st.session_state['research_context'] = {
        'topic': '',
        'variables': '',
        'method': '',
        'references': ''
    }

# -----------------------------------------------------------
# 2. ì‚¬ì´ë“œë°”: ë¡œê·¸ì¸ & ì„¤ì •
# -----------------------------------------------------------
with st.sidebar:
    st.header("ğŸ” ì—°êµ¬ì‹¤ ì…ì¥")
    code = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password")
    if code not in st.secrets["ACCESS_CODES"]:
        st.warning("ì—°êµ¬ì› ì ‘ì† ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.")
        st.stop()
    st.success("ì‹œìŠ¤í…œ ê°€ë™ ì¤‘ (Research Mode)")
    
    # ëª¨ë¸ í™•ì¸ (ë¹„ìƒìš©)
    with st.expander("ğŸ› ï¸ ì‹œìŠ¤í…œ ìƒíƒœ"):
        if st.button("Gemini ëª¨ë¸ ì ê²€"):
            try:
                models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
                st.write(models)
            except:
                st.error("í‚¤ ì—°ê²° í™•ì¸ í•„ìš”")

# API í‚¤ ì—°ê²°
openai.api_key = st.secrets["OPENAI_API_KEY"]
genai.configure(api_key=st.secrets["GEMINI_API_KEY"])

# -----------------------------------------------------------
# 3. AI ë‘ë‡Œ ì •ì˜ (ê° ë‹¨ê³„ë³„ ì „ë¬¸ê°€)
# -----------------------------------------------------------

# [Brain 1] ë³€ì¸ ì„¤ì • ì»¨ì„¤í„´íŠ¸ (GPT)
def consult_variables(topic):
    prompt = f"""
    ë‹¹ì‹ ì€ ì‹¬ë¦¬í•™ ì—°êµ¬ ë°©ë²•ë¡  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ì‚¬ìš©ìê°€ ì…ë ¥í•œ ê´€ì‹¬ ì£¼ì œ: '{topic}'
    
    ì´ ì£¼ì œë¥¼ ì—°êµ¬í•˜ê¸° ìœ„í•œ ì ì ˆí•œ 'ë³€ì¸ êµ¬ì¡°'ë¥¼ 3ê°€ì§€ ì˜µì…˜ìœ¼ë¡œ ì œì•ˆí•´ì£¼ì„¸ìš”.
    ê° ì˜µì…˜ì€ ë‹¤ìŒì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:
    1. ë…ë¦½ë³€ì¸ (IV)
    2. ì¢…ì†ë³€ì¸ (DV)
    3. ë§¤ê°œë³€ì¸ ë˜ëŠ” ì¡°ì ˆë³€ì¸ (Mediator/Moderator)
    4. ì—°êµ¬ ê°€ì„¤ ì˜ˆì‹œ 1ê°œ
    
    ì¶œë ¥ í˜•ì‹ì€ ê¹”ë”í•˜ê²Œ ì •ë¦¬í•´ì„œ ë³´ì—¬ì£¼ì„¸ìš”.
    """
    response = openai.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content

# [Brain 2] ì—°êµ¬ ë°©ë²•ë¡  ì„¤ê³„ì (GPT)
def design_methodology(vars_text):
    prompt = f"""
    ë‹¹ì‹ ì€ í†µê³„ ë¶„ì„ ë° ì²™ë„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    í™•ì •ëœ ë³€ì¸ êµ¬ì¡°:
    {vars_text}
    
    ìœ„ ë³€ì¸ë“¤ì„ ì¸¡ì •í•˜ê³  ë¶„ì„í•˜ê¸° ìœ„í•œ êµ¬ì²´ì ì¸ ë°©ë²•ì„ ì œì•ˆí•˜ì„¸ìš”:
    1. ê° ë³€ì¸ì„ ì¸¡ì •í•  ìˆ˜ ìˆëŠ” ì‹ ë¢°ë„ ë†’ì€ ì²™ë„(Scale) ì¶”ì²œ (êµ¬ì²´ì ì¸ ì²™ë„ëª… ê¸°ì¬)
    2. ë°ì´í„° ìˆ˜ì§‘ ëŒ€ìƒ ë° ì ˆì°¨
    3. ë¶„ì„ ë°©ë²• (ì˜ˆ: ì¤‘ë‹¤íšŒê·€ë¶„ì„, êµ¬ì¡°ë°©ì •ì‹ ë“±)
    """
    response = openai.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content

# [Brain 3] ì„ í–‰ ì—°êµ¬ íƒìƒ‰ê¸° (Gemini 2.5)
def search_literature(topic, vars_text):
    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
        prompt = f"""
        ì£¼ì œ: {topic}
        ë³€ì¸: {vars_text}
        
        ìœ„ ì—°êµ¬ë¥¼ ë’·ë°›ì¹¨í•  ìˆ˜ ìˆëŠ” 'ìµœì‹  ì„ í–‰ ì—°êµ¬(2020-2026)'ì™€ 'í•µì‹¬ ì´ë¡ 'ì„ ì°¾ì•„ì£¼ì„¸ìš”.
        íŠ¹íˆ ì œì•ˆëœ ë³€ì¸ ê°„ì˜ ê´€ê³„ë¥¼ ì§€ì§€í•˜ëŠ” ì—°êµ¬ë“¤ì„ ì¤‘ì‹¬ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
        """
        response = model.generate_content(prompt)
        return response.text
    except:
        # 2.5ê°€ ì•ˆë˜ë©´ proë¡œ ìë™ ì „í™˜
        model = genai.GenerativeModel('gemini-pro')
        response = model.generate_content(prompt)
        return response.text

# [Brain 4] ë…¼ë¬¸ ì‘ì„±ê¸° (GPT)
def write_paper_final(section, context_data):
    prompt = f"""
    [ì—­í• ]: APA ìŠ¤íƒ€ì¼ ì‹¬ë¦¬í•™ ë…¼ë¬¸ ì‘ì„±
    [ì‘ì„± ì±•í„°]: {section}
    
    [í™œìš©í•  ì—°êµ¬ ë°ì´í„°]:
    - ì£¼ì œ: {st.session_state['research_context']['topic']}
    - ë³€ì¸ ì„¤ì •: {st.session_state['research_context']['variables']}
    - ì—°êµ¬ ë°©ë²•: {st.session_state['research_context']['method']}
    - ì„ í–‰ ì—°êµ¬: {context_data}
    
    ìœ„ ì •ë³´ë¥¼ ëª¨ë‘ ì¢…í•©í•˜ì—¬, ë…¼ë¬¸ì˜ '{section}' íŒŒíŠ¸ë¥¼ í•™ìˆ ì ìœ¼ë¡œ ì„œìˆ í•˜ì„¸ìš”.
    """
    response = openai.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content

# -----------------------------------------------------------
# 4. í™”ë©´ êµ¬ì„± (íƒ­ ë°©ì‹ ë„ì…)
# -----------------------------------------------------------
st.title("ğŸ“ MJP: ì‹¬ë¦¬í•™ ì—°êµ¬ ì„¤ê³„ ë° ì‘ì„± ì‹œìŠ¤í…œ")
st.info("ğŸ’¡ ì—°êµ¬ ì„¤ê³„(ë³€ì¸) -> ë°©ë²•ë¡  -> ìë£Œ ì¡°ì‚¬ -> ë…¼ë¬¸ ì‘ì„± ìˆœì„œë¡œ ì§„í–‰í•˜ì„¸ìš”.")

# íƒ­ ë§Œë“¤ê¸°
tab1, tab2, tab3, tab4 = st.tabs(["1. ë³€ì¸ ì„¤ì •", "2. ì—°êµ¬ ë°©ë²•", "3. ì„ í–‰ ì—°êµ¬", "4. ë…¼ë¬¸ ì‘ì„±"])

# --- [Tab 1] ë³€ì¸ ì„¤ì • ---
with tab1:
    st.header("ğŸ§  1ë‹¨ê³„: ë¬´ì—‡ì„ ì—°êµ¬í• ê¹Œìš”?")
    topic_input = st.text_input("ê´€ì‹¬ ìˆëŠ” í‚¤ì›Œë“œë‚˜ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì§ë¬´ ìŠ¤íŠ¸ë ˆìŠ¤ì™€ ì´ì§ ì˜ë„)")
    
    if st.button("ë³€ì¸ êµ¬ì¡° ì œì•ˆë°›ê¸°"):
        with st.spinner("GPTê°€ ì—°êµ¬ ëª¨í˜•ì„ êµ¬ìƒ ì¤‘ì…ë‹ˆë‹¤..."):
            result = consult_variables(topic_input)
            st.success("ì¶”ì²œ ì—°êµ¬ ëª¨í˜•ì…ë‹ˆë‹¤. ë§ˆìŒì— ë“œëŠ” ê²ƒì„ ì„ íƒí•´ ì•„ë˜ì— ì ì–´ì£¼ì„¸ìš”.")
            st.markdown(result)
            st.session_state['research_context']['topic'] = topic_input

    st.subheader("ğŸ“Œ í™•ì •ëœ ë³€ì¸ (ì—¬ê¸°ì— ì •ë¦¬í•´ì„œ ì ì–´ì£¼ì„¸ìš”)")
    final_vars = st.text_area("ì˜ˆ: IV-ì§ë¬´ìŠ¤íŠ¸ë ˆìŠ¤, DV-ì´ì§ì˜ë„, MV-íšŒë³µíƒ„ë ¥ì„±", height=100)
    if st.button("ë³€ì¸ í™•ì • ì €ì¥"):
        st.session_state['research_context']['variables'] = final_vars
        st.success("ë³€ì¸ ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤! ë‹¤ìŒ íƒ­ìœ¼ë¡œ ì´ë™í•˜ì„¸ìš”.")

# --- [Tab 2] ì—°êµ¬ ë°©ë²• ---
with tab2:
    st.header("ğŸ“ 2ë‹¨ê³„: ì–´ë–»ê²Œ ì¸¡ì •í• ê¹Œìš”?")
    st.write(f"í˜„ì¬ ì„¤ì •ëœ ë³€ì¸: **{st.session_state['research_context']['variables']}**")
    
    if st.button("ë°©ë²•ë¡  ë° ì²™ë„ ì¶”ì²œë°›ê¸°"):
        if not st.session_state['research_context']['variables']:
            st.error("1ë‹¨ê³„ì—ì„œ ë³€ì¸ì„ ë¨¼ì € í™•ì •í•´ì£¼ì„¸ìš”!")
        else:
            with st.spinner("ì ì ˆí•œ ì²™ë„ì™€ ë¶„ì„ ë°©ë²•ì„ ì°¾ëŠ” ì¤‘..."):
                method_result = design_methodology(st.session_state['research_context']['variables'])
                st.markdown(method_result)
    
    st.subheader("ğŸ“Œ í™•ì •ëœ ì—°êµ¬ ë°©ë²•")
    final_method = st.text_area("ì‚¬ìš©í•  ì²™ë„ì™€ ë¶„ì„ ë°©ë²•ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”", height=100)
    if st.button("ë°©ë²•ë¡  í™•ì • ì €ì¥"):
        st.session_state['research_context']['method'] = final_method
        st.success("ë°©ë²•ë¡ ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤! ë‹¤ìŒ íƒ­ìœ¼ë¡œ ì´ë™í•˜ì„¸ìš”.")

# --- [Tab 3] ì„ í–‰ ì—°êµ¬ ---
with tab3:
    st.header("ğŸ” 3ë‹¨ê³„: ê·¼ê±° ìë£Œ ì°¾ê¸° (Gemini)")
    
    if st.button("ê´€ë ¨ ì„ í–‰ ì—°êµ¬ ê²€ìƒ‰"):
        topic = st.session_state['research_context']['topic']
        vars_text = st.session_state['research_context']['variables']
        
        if not topic or not vars_text:
            st.error("ì• ë‹¨ê³„ì˜ ì„¤ì •ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        else:
            with st.spinner("Gemini 2.5ê°€ ë…¼ë¬¸ì„ ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤..."):
                refs = search_literature(topic, vars_text)
                st.text_area("ê²€ìƒ‰ ê²°ê³¼", refs, height=500)
                st.session_state['research_context']['references'] = refs

# --- [Tab 4] ë…¼ë¬¸ ì‘ì„± ---
with tab4:
    st.header("âœï¸ 4ë‹¨ê³„: ë…¼ë¬¸ ì“°ê¸° (ì¢…í•©)")
    
    section = st.selectbox("ì‘ì„±í•  ì±•í„°", ["ì„œë¡  (ì—°êµ¬ì˜ í•„ìš”ì„±)", "ì´ë¡ ì  ë°°ê²½", "ì—°êµ¬ ë°©ë²•", "ê²°ê³¼ (ì˜ˆìƒ)", "ë…¼ì˜"])
    
    if st.button("AI ì´ˆì•ˆ ì‘ì„± ì‹œì‘"):
        # ì €ì¥ëœ ëª¨ë“  ë§¥ë½ì„ ê°€ì ¸ì˜´
        context = st.session_state['research_context']['references']
        
        if not context:
            st.warning("3ë‹¨ê³„ì—ì„œ ì„ í–‰ ì—°êµ¬ ê²€ìƒ‰ì„ ë¨¼ì € í•´ì£¼ì„¸ìš”. (ê·¼ê±° ì—†ëŠ” ê¸€ì“°ê¸°ëŠ” ìœ„í—˜í•©ë‹ˆë‹¤)")
        else:
            with st.spinner(f"ì„¤ê³„ëœ ë‚´ìš©(ë³€ì¸, ë°©ë²•)ì„ ë°”íƒ•ìœ¼ë¡œ '{section}' ì‘ì„± ì¤‘..."):
                draft = write_paper_final(section, context)
                st.markdown(draft)