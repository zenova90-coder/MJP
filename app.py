import streamlit as st
import openai
import google.generativeai as genai

# -----------------------------------------------------------
# 1. ìŠ¤íƒ€ì¼ & ê¸°ë³¸ ì„¤ì •
# -----------------------------------------------------------
st.set_page_config(page_title="MJP Pro: ì—°êµ¬ í† ë¡  íŒŒíŠ¸ë„ˆ", layout="wide")

st.markdown("""
<style>
    div.stButton > button:first-child {
        background-color: #0068c9;
        color: white;
        border-radius: 6px;
        font-weight: bold;
    }
    div.stButton > button:first-child:hover {
        background-color: #004b91;
    }
    /* í† í° í‘œì‹œ ë””ìì¸ */
    .token-box {
        padding: 10px;
        background-color: #f0f2f6;
        border-radius: 10px;
        text-align: center;
        margin-bottom: 20px;
        border: 2px solid #0068c9;
    }
    .token-text {
        font-size: 20px;
        font-weight: bold;
        color: #0068c9;
    }
</style>
""", unsafe_allow_html=True)

# -----------------------------------------------------------
# 2. ë°ì´í„° ì €ì¥ì†Œ & í† í° ì‹œìŠ¤í…œ ì´ˆê¸°í™”
# -----------------------------------------------------------
# [NEW] í† í° ì‹œìŠ¤í…œ
if 'user_tokens' not in st.session_state:
    st.session_state['user_tokens'] = 1000  # ì‹ ê·œ ê°€ì… ì¶•í•˜ê¸ˆ

if 'research_context' not in st.session_state:
    st.session_state['research_context'] = {
        'topic': '', 'variables_options': [], 'variables': '',
        'method_options': [], 'method': '', 'references': ''
    }

if 'paper_sections' not in st.session_state:
    st.session_state['paper_sections'] = {
        "ì„œë¡ ": "", "ì´ë¡ ì  ë°°ê²½": "", "ì—°êµ¬ ë°©ë²•": "", "ê²°ê³¼": "", "ë…¼ì˜": ""
    }

if "chat_history_step0" not in st.session_state:
    st.session_state.chat_history_step0 = []

if "messages_helper" not in st.session_state:
    st.session_state.messages_helper = []

# -----------------------------------------------------------
# 3. ì‚¬ì´ë“œë°”: ë¡œê·¸ì¸ & ê²°ì œ ì‹œìŠ¤í…œ (ì¶©ì „ì†Œ)
# -----------------------------------------------------------
with st.sidebar:
    st.header("ğŸ” ì—°êµ¬ì‹¤ ì…ì¥")
    code = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password")
    if code not in st.secrets["ACCESS_CODES"]:
        st.warning("ì—°êµ¬ì› ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.")
        st.stop()
    st.success("ë¡œê·¸ì¸ ì™„ë£Œ")

    st.markdown("---")
    
    # ğŸ’° [NEW] í† í° ì¶©ì „ì†Œ
    st.header("ğŸ”‹ í† í° ì¶©ì „ì†Œ")
    
    # í˜„ì¬ ì”ì•¡ í‘œì‹œ (ì‚¬ì´ë“œë°”)
    st.metric(label="í˜„ì¬ ë³´ìœ  í† í°", value=f"{st.session_state['user_tokens']} T")
    
    with st.expander("ğŸ’³ í† í° ì¶©ì „í•˜ê¸° (ê²°ì œ)"):
        st.write("í† í°ì´ ë¶€ì¡±í•œê°€ìš”? ì•„ë˜ ê³„ì¢Œë¡œ ì…ê¸ˆ í›„ ê´€ë¦¬ìì—ê²Œ ì—°ë½ì£¼ì„¸ìš”.")
        st.code("ì¹´ì¹´ì˜¤ë±…í¬ 3333-XX-XXXXXX (ì˜ˆê¸ˆì£¼: ë¯¼ì£¼)") # [ìˆ˜ì •í•„ìš”] ë³¸ì¸ ê³„ì¢Œë¡œ ë³€ê²½
        st.markdown("[ğŸ“² ì¹´ì¹´ì˜¤í˜ì´ë¡œ ì†¡ê¸ˆí•˜ê¸°](https://qr.kakaopay.com/...)") # [ìˆ˜ì •í•„ìš”] ë§í¬ ë„£ê¸°
        st.info("ì…ê¸ˆ í›„ ë°›ì€ ì¿ í° ì½”ë“œë¥¼ ì•„ë˜ì— ì…ë ¥í•˜ì„¸ìš”.")
        
        # ì¿ í° ì…ë ¥ ì‹œìŠ¤í…œ
        coupon = st.text_input("ì¿ í° ì½”ë“œ ì…ë ¥")
        if st.button("ì¶©ì „ ì ìš©"):
            if coupon == "MJP-LOVE-2026":
                st.session_state['user_tokens'] += 5000
                st.balloons()
                st.success("5,000 í† í°ì´ ì¶©ì „ë˜ì—ˆìŠµë‹ˆë‹¤!")
            elif coupon == "ADMIN-POWER":
                st.session_state['user_tokens'] += 10000
                st.success("10,000 í† í° ì¶©ì „ ì™„ë£Œ!")
            else:
                st.error("ìœ íš¨í•˜ì§€ ì•Šì€ ì¿ í°ì…ë‹ˆë‹¤.")
                
    st.markdown("---")
    if st.button("ğŸ—‘ï¸ ì´ˆê¸°í™”", type="primary"):
        for key in st.session_state.keys():
            del st.session_state[key]
        st.rerun()

openai.api_key = st.secrets["OPENAI_API_KEY"]
genai.configure(api_key=st.secrets["GEMINI_API_KEY"])

# -----------------------------------------------------------
# 4. ê¸°ëŠ¥ í•¨ìˆ˜ (í† í° ì°¨ê° ë¡œì§ ì¶”ê°€)
# -----------------------------------------------------------
# í† í° ì°¨ê° ë„ìš°ë¯¸ í•¨ìˆ˜
def check_and_deduct_tokens(cost):
    if st.session_state['user_tokens'] >= cost:
        st.session_state['user_tokens'] -= cost
        return True
    else:
        st.error(f"í† í°ì´ ë¶€ì¡±í•©ë‹ˆë‹¤! (í•„ìš”: {cost}, ë³´ìœ : {st.session_state['user_tokens']}) ì‚¬ì´ë“œë°”ì—ì„œ ì¶©ì „í•˜ì„¸ìš”.")
        return False

def consult_variables_options(topic):
    prompt = f"ì£¼ì œ '{topic}' ë³€ì¸ êµ¬ì¡° 3ê°€ì§€ ì œì•ˆ (êµ¬ë¶„ì |||)"
    response = openai.chat.completions.create(model="gpt-4o-mini", messages=[{"role": "user", "content": prompt}])
    return [opt.strip() for opt in response.choices[0].message.content.split("|||") if opt.strip()]

def design_methodology_options(vars_text):
    prompt = f"ë³€ì¸ '{vars_text}' ë°©ë²•ë¡  3ê°€ì§€ ì œì•ˆ (êµ¬ë¶„ì |||)"
    response = openai.chat.completions.create(model="gpt-4o-mini", messages=[{"role": "user", "content": prompt}])
    return [opt.strip() for opt in response.choices[0].message.content.split("|||") if opt.strip()]

def search_literature(topic, vars_text):
    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
        prompt = f"ì£¼ì œ: {topic}, ë³€ì¸: {vars_text}. ì„ í–‰ ì—°êµ¬ ê²€ìƒ‰."
        return model.generate_content(prompt).text
    except: return "ê²€ìƒ‰ ì˜¤ë¥˜"

def write_paper_final(section, context_data):
    prompt = f"[APA ìŠ¤íƒ€ì¼] '{section}' ì‘ì„±. ê·¼ê±°: {context_data}"
    response = openai.chat.completions.create(model="gpt-4o-mini", messages=[{"role": "user", "content": prompt}])
    return response.choices[0].message.content

def organize_references_apa(raw_text):
    prompt = f"ì°¸ê³ ë¬¸í—Œ APA ë³€í™˜ ë° ì •ë ¬:\n{raw_text}"
    response = openai.chat.completions.create(model="gpt-4o-mini", messages=[{"role": "user", "content": prompt}])
    return response.choices[0].message.content

# -----------------------------------------------------------
# 5. [ìˆ˜ì •ë¨] ì—ëŸ¬ ì—†ëŠ” ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ (Key ì¶”ê°€!)
# -----------------------------------------------------------
def render_chat_interface(stage_name, user_input_content, ai_suggestions_content="", unique_key="default"):
    st.markdown(f"#### ğŸ’¬ AI ì¡°êµ ({stage_name})")
    st.caption("ğŸ‘ˆ ì™¼ìª½ ë‚´ìš©ì„ ë‹¤ ë³´ê³  ìˆìŠµë‹ˆë‹¤.")
    
    with st.container(height=450):
        # í˜„ì¬ ë‹¨ê³„ì— ë§ëŠ” ëŒ€í™”ë§Œ ë³´ì—¬ì£¼ë©´ ì¢‹ê² ì§€ë§Œ, ì¼ë‹¨ ì „ì²´ ê³µìœ  (ê°„ì†Œí™”)
        for message in st.session_state.messages_helper:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

    # [í•µì‹¬ ìˆ˜ì •] key=unique_keyë¥¼ ì¶”ê°€í•˜ì—¬ ì¤‘ë³µ ì—ëŸ¬ í•´ê²°!
    if prompt := st.chat_input("ì§ˆë¬¸í•˜ê¸°...", key=unique_key):
        
        # ì±„íŒ…ë„ í† í° ì†Œëª¨ (ì‹¸ê²Œ 10í† í°)
        if not check_and_deduct_tokens(10):
            st.stop()
            
        st.session_state.messages_helper.append({"role": "user", "content": prompt})
        
        full_context = f"ë‹¨ê³„: {stage_name}\në‚´ìš©: {user_input_content}\nì˜µì…˜: {ai_suggestions_content}\nì§ˆë¬¸: {prompt}"
        
        response = openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "system", "content": "ì¹œì ˆí•œ ì—°êµ¬ ì¡°êµì…ë‹ˆë‹¤."}] + 
                     [{"role": "user", "content": full_context}]
        )
        ai_msg = response.choices[0].message.content
        st.session_state.messages_helper.append({"role": "assistant", "content": ai_msg})
        st.rerun()

# -----------------------------------------------------------
# 6. ë©”ì¸ í™”ë©´ êµ¬ì„± (í† í° ì”ì•¡ ëŒ€ì‹œë³´ë“œ ì¶”ê°€)
# -----------------------------------------------------------
st.title("ğŸ“ MJP: ì—°êµ¬ í† ë¡  & ì„¤ê³„ ì‹œìŠ¤í…œ (Biz)")

# [NEW] ì¤‘ì•™ í† í° ëŒ€ì‹œë³´ë“œ
st.markdown(f"""
<div class="token-box">
    <span>ğŸ’ í˜„ì¬ ë³´ìœ  í† í°: </span>
    <span class="token-text">{st.session_state['user_tokens']} T</span>
    <span style="font-size: 14px; color: gray;"> (AI ì‚¬ìš© ì‹œ ì°¨ê°ë©ë‹ˆë‹¤)</span>
</div>
""", unsafe_allow_html=True)


tabs = st.tabs(["ğŸ’¡ 0. í† ë¡ ", "1. ë³€ì¸", "2. ë°©ë²•", "3. ê²€ìƒ‰", "4. ì‘ì„±", "5. ì°¸ê³ ë¬¸í—Œ"])

# [Tab 0] í† ë¡ 
with tabs[0]:
    st.header("ğŸ’¡ 0ë‹¨ê³„: ì—°êµ¬ ì•„ì´ë””ì–´ í† ë¡ ")
    for msg in st.session_state.chat_history_step0:
        with st.chat_message(msg["role"]): st.markdown(msg["content"])

    # [í•µì‹¬ ìˆ˜ì •] key ì¶”ê°€
    if prompt := st.chat_input("ì•„ì´ë””ì–´ í† ë¡ í•˜ê¸°...", key="chat_tab0"):
        if check_and_deduct_tokens(20): # í† ë¡ ì€ 20í† í°
            st.session_state.chat_history_step0.append({"role": "user", "content": prompt})
            with st.chat_message("user"): st.markdown(prompt)
            with st.chat_message("assistant"):
                with st.spinner("ìƒê° ì¤‘..."):
                    res = openai.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=[{"role": "system", "content": "ì‹¬ë¦¬í•™ ì—°êµ¬íŒ€ì…ë‹ˆë‹¤."}] + 
                                 [{"role": m["role"], "content": m["content"]} for m in st.session_state.chat_history_step0]
                    )
                    st.markdown(res.choices[0].message.content)
                    st.session_state.chat_history_step0.append({"role": "assistant", "content": res.choices[0].message.content})
                    st.rerun() # ì”ì•¡ ê°±ì‹  ìœ„í•´

# [Tab 1] ë³€ì¸
with tabs[1]:
    col_main, col_chat = st.columns([6, 4])
    with col_main:
        st.subheader("ğŸ§  1ë‹¨ê³„: ë³€ì¸ í™•ì •")
        final_vars = st.text_area("ìµœì¢… ë³€ì¸", value=st.session_state['research_context']['variables'], height=150)
        if st.button("âœ… ì €ì¥", type="primary", key="save_v"):
            st.session_state['research_context']['variables'] = final_vars
            st.success("ì €ì¥ë¨")
            
        topic = st.text_input("ì£¼ì œ", value=st.session_state['research_context']['topic'])
        if st.button("ğŸ¤– 3ê°€ì§€ ì œì•ˆ (50í† í°)", key="gen_v"):
            if check_and_deduct_tokens(50):
                with st.spinner("ìƒì„± ì¤‘..."):
                    opts = consult_variables_options(topic)
                    st.session_state['research_context']['variables_options'] = opts
                    st.session_state['research_context']['topic'] = topic
                    st.rerun()

        if st.session_state['research_context']['variables_options']:
            choice = st.radio("ì„ íƒ:", st.session_state['research_context']['variables_options'])
            if st.button("ğŸ”¼ ì ìš©", key="apply_v"):
                st.session_state['research_context']['variables'] = choice
                st.rerun()

    with col_chat:
        # [í•µì‹¬ ìˆ˜ì •] key="chat_tab1" ì „ë‹¬
        render_chat_interface("1ë‹¨ê³„", st.session_state['research_context']['variables'], 
                            str(st.session_state['research_context']['variables_options']), unique_key="chat_tab1")

# [Tab 2] ë°©ë²•
with tabs[2]:
    col_main, col_chat = st.columns([6, 4])
    with col_main:
        st.subheader("ğŸ“ 2ë‹¨ê³„: ë°©ë²• í™•ì •")
        final_method = st.text_area("ìµœì¢… ë°©ë²•", value=st.session_state['research_context']['method'], height=150)
        if st.button("âœ… ì €ì¥", type="primary", key="save_m"):
            st.session_state['research_context']['method'] = final_method
            st.success("ì €ì¥ë¨")
            
        if st.button("ğŸ¤– 3ê°€ì§€ ì œì•ˆ (50í† í°)", key="gen_m"):
            if check_and_deduct_tokens(50):
                with st.spinner("ì„¤ê³„ ì¤‘..."):
                    opts = design_methodology_options(st.session_state['research_context']['variables'])
                    st.session_state['research_context']['method_options'] = opts
                    st.rerun()
        
        if st.session_state['research_context']['method_options']:
            choice = st.radio("ì„ íƒ:", st.session_state['research_context']['method_options'])
            if st.button("ğŸ”¼ ì ìš©", key="apply_m"):
                st.session_state['research_context']['method'] = choice
                st.rerun()

    with col_chat:
        render_chat_interface("2ë‹¨ê³„", st.session_state['research_context']['method'], 
                            str(st.session_state['research_context']['method_options']), unique_key="chat_tab2")

# [Tab 3] ê²€ìƒ‰
with tabs[3]:
    col_main, col_chat = st.columns([6, 4])
    with col_main:
        st.subheader("ğŸ” 3ë‹¨ê³„: ê²€ìƒ‰")
        if st.button("ğŸš€ Gemini ê²€ìƒ‰ (30í† í°)", type="primary"):
            if check_and_deduct_tokens(30):
                with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                    refs = search_literature(st.session_state['research_context']['topic'], st.session_state['research_context']['variables'])
                    st.session_state['research_context']['references'] = refs
                    st.rerun()
        st.text_area("ê²°ê³¼", value=st.session_state['research_context']['references'], height=500)

    with col_chat:
        render_chat_interface("3ë‹¨ê³„", st.session_state['research_context']['references'], unique_key="chat_tab3")

# [Tab 4] ì‘ì„±
with tabs[4]:
    col_main, col_chat = st.columns([6, 4])
    with col_main:
        st.subheader("âœï¸ 4ë‹¨ê³„: ì‘ì„±")
        sec = st.selectbox("ì±•í„°", list(st.session_state['paper_sections'].keys()))
        if st.button(f"ğŸ¤– {sec} ì‘ì„± (100í† í°)", type="primary"):
            if check_and_deduct_tokens(100):
                with st.spinner("ì‘ì„± ì¤‘..."):
                    draft = write_paper_final(sec, st.session_state['research_context']['references'])
                    st.session_state['paper_sections'][sec] = draft
                    st.rerun()
        current = st.text_area("í¸ì§‘ê¸°", value=st.session_state['paper_sections'][sec], height=600)
        if st.button("ğŸ’¾ ì €ì¥", key="save_sec"):
            st.session_state['paper_sections'][sec] = current
            st.success("ì €ì¥ë¨")

    with col_chat:
        render_chat_interface(f"4ë‹¨ê³„({sec})", st.session_state['paper_sections'][sec], unique_key="chat_tab4")

# [Tab 5] ì°¸ê³ ë¬¸í—Œ
with tabs[5]:
    col_main, col_chat = st.columns([6, 4])
    with col_main:
        if st.button("âœ¨ ë³€í™˜ (20í† í°)", type="primary"):
            if check_and_deduct_tokens(20):
                res = organize_references_apa(st.session_state['research_context']['references'])
                st.markdown(res)
    with col_chat:
        render_chat_interface("5ë‹¨ê³„", "ì°¸ê³ ë¬¸í—Œ ì‘ì—…", unique_key="chat_tab5")